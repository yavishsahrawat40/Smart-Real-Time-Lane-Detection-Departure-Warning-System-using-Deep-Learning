{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-30T18:46:59.826971Z",
     "iopub.status.busy": "2025-10-30T18:46:59.826276Z",
     "iopub.status.idle": "2025-10-30T18:46:59.831031Z",
     "shell.execute_reply": "2025-10-30T18:46:59.830255Z",
     "shell.execute_reply.started": "2025-10-30T18:46:59.826945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T18:43:33.319486Z",
     "iopub.status.busy": "2025-10-30T18:43:33.319102Z",
     "iopub.status.idle": "2025-10-30T18:43:33.388498Z",
     "shell.execute_reply": "2025-10-30T18:43:33.387587Z",
     "shell.execute_reply.started": "2025-10-30T18:43:33.319462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model path: /kaggle/input/culane-trained-model/culane_trainedModel/best_model_culane.pth.tar\n",
      "Dataset path: /kaggle/input/culane\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"/kaggle/input/culane-trained-model/culane_trainedModel/best_model_culane.pth.tar\" \n",
    "CULANE_ROOT = \"/kaggle/input/culane\"\n",
    "EVAL_ANNOTATION_FILE = \"/kaggle/input/culane/CULane/culane_val_annotations.json\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 160, 320 \n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model path: {CHECKPOINT_PATH}\")\n",
    "print(f\"Dataset path: {CULANE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T18:50:56.025503Z",
     "iopub.status.busy": "2025-10-30T18:50:56.025239Z",
     "iopub.status.idle": "2025-10-30T18:50:56.038017Z",
     "shell.execute_reply": "2025-10-30T18:50:56.037214Z",
     "shell.execute_reply.started": "2025-10-30T18:50:56.025483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DATASET AND MODEL DEFINITIONS\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, annotation_path, root_dir, transform=None):\n",
    "        with open(annotation_path, 'r') as f: self.annotations = json.load(f)\n",
    "        self.root_dir = root_dir; self.transform = transform\n",
    "    def __len__(self): return len(self.annotations)\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]; img_rel_path = ann['image'].replace('\\\\', '/'); mask_rel_path = ann['mask'].replace('\\\\', '/')\n",
    "        img_path = os.path.join(self.root_dir, img_rel_path); mask_path = os.path.join(self.root_dir, mask_rel_path)\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert(\"RGB\")); mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        except FileNotFoundError:\n",
    "            image = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=np.uint8); mask = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.uint8)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask); image = augmented[\"image\"]; mask = augmented[\"mask\"]\n",
    "        return image, (mask > 0).float().unsqueeze(0)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        for feature in features:\n",
    "            self.downs.append(self.double_conv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        self.bottleneck = self.double_conv(features[-1], features[-1] * 2)\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(self.double_conv(feature * 2, feature))\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:])\n",
    "            x = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx + 1](x)\n",
    "        return self.final_conv(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def double_conv(in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T18:50:58.466173Z",
     "iopub.status.busy": "2025-10-30T18:50:58.465609Z",
     "iopub.status.idle": "2025-10-30T18:50:58.472884Z",
     "shell.execute_reply": "2025-10-30T18:50:58.472289Z",
     "shell.execute_reply.started": "2025-10-30T18:50:58.466150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# INSTANCE-LEVEL METRIC FUNCTIONS\n",
    "def calculate_instance_iou(mask1, mask2, smooth=1e-6):\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def calculate_instance_metrics(pred_mask, gt_mask, iou_threshold=0.5):\n",
    "    num_pred_labels, pred_labels = cv2.connectedComponents(pred_mask)\n",
    "    num_gt_labels, gt_labels = cv2.connectedComponents(gt_mask)\n",
    "    \n",
    "    if num_pred_labels <= 1 and num_gt_labels <= 1: return {'tp': 0, 'fp': 0, 'fn': 0}\n",
    "\n",
    "    iou_matrix = np.zeros((num_pred_labels - 1, num_gt_labels - 1))\n",
    "    for i in range(1, num_pred_labels):\n",
    "        for j in range(1, num_gt_labels):\n",
    "            pred_instance = (pred_labels == i).astype(np.uint8)\n",
    "            gt_instance = (gt_labels == j).astype(np.uint8)\n",
    "            iou_matrix[i-1, j-1] = calculate_instance_iou(pred_instance, gt_instance)\n",
    "    \n",
    "    matches = []\n",
    "    if iou_matrix.size > 0:\n",
    "        for j in range(iou_matrix.shape[1]): \n",
    "            best_iou_for_gt = iou_matrix[:, j].max()\n",
    "            if best_iou_for_gt > iou_threshold:\n",
    "                pred_idx = iou_matrix[:, j].argmax()\n",
    "                if pred_idx not in [m[0] for m in matches]:\n",
    "                    matches.append((pred_idx, j))\n",
    "\n",
    "    tp = len(matches)\n",
    "    fp = (num_pred_labels - 1) - tp\n",
    "    fn = (num_gt_labels - 1) - tp\n",
    "    \n",
    "    return {'tp': tp, 'fp': fp, 'fn': fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T18:50:59.255505Z",
     "iopub.status.busy": "2025-10-30T18:50:59.255239Z",
     "iopub.status.idle": "2025-10-30T18:50:59.264790Z",
     "shell.execute_reply": "2025-10-30T18:50:59.264097Z",
     "shell.execute_reply.started": "2025-10-30T18:50:59.255485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"ðŸš€ Starting CULane model evaluation (Instance-Level)...\")\n",
    "    \n",
    "    model = UNet(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    \n",
    "    print(f\"Loading model from checkpoint: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    eval_transform = A.Compose([\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    eval_dataset = LaneDataset(annotation_path=EVAL_ANNOTATION_FILE, root_dir=CULANE_ROOT, transform=eval_transform)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    print(f\"Loaded {len(eval_dataset)} images for evaluation.\")\n",
    "\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(eval_loader, desc=\"Evaluating Instances\"):\n",
    "            images = images.to(DEVICE)\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5)\n",
    "\n",
    "            for i in range(preds.shape[0]):\n",
    "                pred_mask = preds[i].squeeze().cpu().numpy().astype(np.uint8)\n",
    "                gt_mask = targets[i].squeeze().cpu().numpy().astype(np.uint8)\n",
    "                \n",
    "                metrics = calculate_instance_metrics(pred_mask, gt_mask)\n",
    "                total_tp += metrics['tp']\n",
    "                total_fp += metrics['fp']\n",
    "                total_fn += metrics['fn']\n",
    "\n",
    "    smooth = 1e-6\n",
    "    precision = (total_tp + smooth) / (total_tp + total_fp + smooth)\n",
    "    recall = (total_tp + smooth) / (total_tp + total_fn + smooth)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    accuracy = (total_tp + smooth) / (total_tp + total_fp + total_fn + smooth)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(\"âœ… CULANE - FINAL INSTANCE-LEVEL METRICS\")\n",
    "    print(\"=\"*45)\n",
    "    print(f\"Total True Positives (Correctly Detected Lanes):  {total_tp}\")\n",
    "    print(f\"Total False Positives (Incorrect Detections): {total_fp}\")\n",
    "    print(f\"Total False Negatives (Missed Lanes):         {total_fn}\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"Accuracy (Paper's Definition): {accuracy:.4f}\")\n",
    "    print(f\"Precision:                     {precision:.4f}\")\n",
    "    print(f\"Recall:                        {recall:.4f}\")\n",
    "    print(f\"F1-Score:                      {f1_score:.4f}\")\n",
    "    print(\"=\"*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T18:51:00.488028Z",
     "iopub.status.busy": "2025-10-30T18:51:00.487436Z",
     "iopub.status.idle": "2025-10-30T18:53:30.106436Z",
     "shell.execute_reply": "2025-10-30T18:53:30.105595Z",
     "shell.execute_reply.started": "2025-10-30T18:51:00.488005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting CULane model evaluation (Instance-Level)...\n",
      "Loading model from checkpoint: /kaggle/input/culane-trained-model/culane_trainedModel/best_model_culane.pth.tar\n",
      "Loaded 9675 images for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Instances: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 605/605 [02:28<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "âœ… CULANE - FINAL INSTANCE-LEVEL METRICS\n",
      "=============================================\n",
      "Total True Positives (Correctly Detected Lanes):  14550\n",
      "Total False Positives (Incorrect Detections): 29899\n",
      "Total False Negatives (Missed Lanes):         14973\n",
      "---------------------------------------------\n",
      "Accuracy (Paper's Definition): 0.2449\n",
      "Precision:                     0.3273\n",
      "Recall:                        0.4928\n",
      "F1-Score:                      0.3934\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8381617,
     "sourceId": 13223304,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8270064,
     "sourceId": 13059617,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
