{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-07T05:57:38.871755Z",
     "iopub.status.busy": "2025-10-07T05:57:38.870982Z",
     "iopub.status.idle": "2025-10-07T05:57:44.088857Z",
     "shell.execute_reply": "2025-10-07T05:57:44.088285Z",
     "shell.execute_reply.started": "2025-10-07T05:57:38.871718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:58:32.302140Z",
     "iopub.status.busy": "2025-10-07T05:58:32.301438Z",
     "iopub.status.idle": "2025-10-07T05:58:32.363305Z",
     "shell.execute_reply": "2025-10-07T05:58:32.362677Z",
     "shell.execute_reply.started": "2025-10-07T05:58:32.302116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model path: /kaggle/input/culane-attention-module-trained-model/culane_attention_module_trained_model/best_model_culane_attention.pth.tar\n",
      "Dataset path: /kaggle/input/culane\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"/kaggle/input/culane-attention-module-trained-model/culane_attention_module_trained_model/best_model_culane_attention.pth.tar\"\n",
    "\n",
    "CULANE_ROOT = \"/kaggle/input/culane\"\n",
    "EVAL_ANNOTATION_FILE = \"/kaggle/input/culane/CULane/culane_val_annotations.json\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 160, 320\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model path: {CHECKPOINT_PATH}\")\n",
    "print(f\"Dataset path: {CULANE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:58:50.659564Z",
     "iopub.status.busy": "2025-10-07T05:58:50.659313Z",
     "iopub.status.idle": "2025-10-07T05:58:50.666495Z",
     "shell.execute_reply": "2025-10-07T05:58:50.665885Z",
     "shell.execute_reply.started": "2025-10-07T05:58:50.659547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DATASET AND MODEL DEFINITIONS \n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, annotation_path, root_dir, transform=None):\n",
    "        with open(annotation_path, 'r') as f: self.annotations = json.load(f)\n",
    "        self.root_dir = root_dir; self.transform = transform\n",
    "    def __len__(self): return len(self.annotations)\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]; img_rel_path = ann['image'].replace('\\\\', '/'); mask_rel_path = ann['mask'].replace('\\\\', '/')\n",
    "        img_path = os.path.join(self.root_dir, img_rel_path); mask_path = os.path.join(self.root_dir, mask_rel_path)\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert(\"RGB\")); mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "        except FileNotFoundError:\n",
    "            image = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 3), dtype=np.uint8); mask = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.uint8)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask); image = augmented[\"image\"]; mask = augmented[\"mask\"]\n",
    "        return image, (mask > 0).float().unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:59:01.571465Z",
     "iopub.status.busy": "2025-10-07T05:59:01.571182Z",
     "iopub.status.idle": "2025-10-07T05:59:01.583030Z",
     "shell.execute_reply": "2025-10-07T05:59:01.582415Z",
     "shell.execute_reply.started": "2025-10-07T05:59:01.571434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(); self.double_conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True), nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False), nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True))\n",
    "    def forward(self, x): return self.double_conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__(); self.W_g = nn.Sequential(nn.Conv2d(F_g, F_int, kernel_size=1, bias=True), nn.BatchNorm2d(F_int)); self.W_x = nn.Sequential(nn.Conv2d(F_l, F_int, kernel_size=1, bias=True), nn.BatchNorm2d(F_int)); self.psi = nn.Sequential(nn.Conv2d(F_int, 1, kernel_size=1, bias=True), nn.BatchNorm2d(1), nn.Sigmoid()); self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, g, x): g1 = self.W_g(g); x1 = self.W_x(x); psi = self.relu(g1 + x1); psi = self.psi(psi); return x * psi\n",
    "\n",
    "class AttentionUNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(AttentionUNET, self).__init__(); self.downs = nn.ModuleList(); self.ups = nn.ModuleList(); self.pool = nn.MaxPool2d(2, 2)\n",
    "        for feature in features: self.downs.append(DoubleConv(in_channels, feature)); in_channels = feature\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        for i, feature in enumerate(reversed(features)): self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)); self.ups.append(AttentionGate(F_g=feature, F_l=feature, F_int=feature // 2)); self.ups.append(DoubleConv(feature * 2, feature))\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        skip_connections = [];\n",
    "        for down in self.downs: x = down(x); skip_connections.append(x); x = self.pool(x)\n",
    "        x = self.bottleneck(x); skip_connections = skip_connections[::-1]\n",
    "        for i in range(0, len(self.ups), 3):\n",
    "            x = self.ups[i](x); skip_connection = skip_connections[i // 3]\n",
    "            att_out = self.ups[i+1](g=x, x=skip_connection)\n",
    "            if x.shape != att_out.shape: x = F.interpolate(x, size=att_out.shape[2:])\n",
    "            x = torch.cat((att_out, x), dim=1); x = self.ups[i+2](x)\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:00:42.974465Z",
     "iopub.status.busy": "2025-10-07T06:00:42.973870Z",
     "iopub.status.idle": "2025-10-07T06:00:42.981872Z",
     "shell.execute_reply": "2025-10-07T06:00:42.981065Z",
     "shell.execute_reply.started": "2025-10-07T06:00:42.974433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# INSTANCE-LEVEL METRIC FUNCTIONS\n",
    "def calculate_instance_iou(mask1, mask2, smooth=1e-6):\n",
    "    \"\"\"Calculates IoU for two single-instance binary masks.\"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def calculate_instance_metrics(pred_mask, gt_mask, iou_threshold=0.5):\n",
    "    \"\"\"Calculates instance-level TP, FP, FN based on IoU threshold.\"\"\"\n",
    "    num_pred_labels, pred_labels = cv2.connectedComponents(pred_mask)\n",
    "    num_gt_labels, gt_labels = cv2.connectedComponents(gt_mask)\n",
    "    \n",
    "    if num_pred_labels <= 1 and num_gt_labels <= 1: return {'tp': 0, 'fp': 0, 'fn': 0}\n",
    "\n",
    "    iou_matrix = np.zeros((num_pred_labels - 1, num_gt_labels - 1))\n",
    "    for i in range(1, num_pred_labels):\n",
    "        for j in range(1, num_gt_labels):\n",
    "            pred_instance = (pred_labels == i).astype(np.uint8)\n",
    "            gt_instance = (gt_labels == j).astype(np.uint8)\n",
    "            iou_matrix[i-1, j-1] = calculate_instance_iou(pred_instance, gt_instance)\n",
    "    \n",
    "    matches = []\n",
    "    if iou_matrix.size > 0:\n",
    "        for j in range(iou_matrix.shape[1]): # For each GT lane\n",
    "            best_iou_for_gt = iou_matrix[:, j].max()\n",
    "            if best_iou_for_gt > iou_threshold:\n",
    "                pred_idx = iou_matrix[:, j].argmax()\n",
    "                if pred_idx not in [m[0] for m in matches]:\n",
    "                    matches.append((pred_idx, j))\n",
    "\n",
    "    tp = len(matches)\n",
    "    fp = (num_pred_labels - 1) - tp\n",
    "    fn = (num_gt_labels - 1) - tp\n",
    "    \n",
    "    return {'tp': tp, 'fp': fp, 'fn': fn}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:00:58.646406Z",
     "iopub.status.busy": "2025-10-07T06:00:58.646137Z",
     "iopub.status.idle": "2025-10-07T06:00:58.655358Z",
     "shell.execute_reply": "2025-10-07T06:00:58.654609Z",
     "shell.execute_reply.started": "2025-10-07T06:00:58.646388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"ðŸš€ Starting CULane model evaluation (Instance-Level)...\")\n",
    "    \n",
    "    model = AttentionUNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    print(f\"Loading model from checkpoint: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    eval_transform = A.Compose([\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    eval_dataset = LaneDataset(annotation_path=EVAL_ANNOTATION_FILE, root_dir=CULANE_ROOT, transform=eval_transform)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    print(f\"Loaded {len(eval_dataset)} images for evaluation.\")\n",
    "\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(eval_loader, desc=\"Evaluating Instances\"):\n",
    "            images = images.to(DEVICE)\n",
    "            preds = torch.sigmoid(model(images))\n",
    "            preds = (preds > 0.5)\n",
    "\n",
    "            for i in range(preds.shape[0]):\n",
    "                pred_mask = preds[i].squeeze().cpu().numpy().astype(np.uint8)\n",
    "                gt_mask = targets[i].squeeze().cpu().numpy().astype(np.uint8)\n",
    "                \n",
    "                metrics = calculate_instance_metrics(pred_mask, gt_mask)\n",
    "                total_tp += metrics['tp']\n",
    "                total_fp += metrics['fp']\n",
    "                total_fn += metrics['fn']\n",
    "\n",
    "    smooth = 1e-6\n",
    "    precision = (total_tp + smooth) / (total_tp + total_fp + smooth)\n",
    "    recall = (total_tp + smooth) / (total_tp + total_fn + smooth)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    accuracy = (total_tp + smooth) / (total_tp + total_fp + total_fn + smooth)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(\"âœ… CULANE - FINAL INSTANCE-LEVEL METRICS\")\n",
    "    print(\"=\"*45)\n",
    "    print(f\"Total True Positives (Correctly Detected Lanes):  {total_tp}\")\n",
    "    print(f\"Total False Positives (Incorrect Detections): {total_fp}\")\n",
    "    print(f\"Total False Negatives (Missed Lanes):         {total_fn}\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"Accuracy (Paper's Definition): {accuracy:.4f}\")\n",
    "    print(f\"Precision:                     {precision:.4f}\")\n",
    "    print(f\"Recall:                        {recall:.4f}\")\n",
    "    print(f\"F1-Score:                      {f1_score:.4f}\")\n",
    "    print(\"=\"*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:01:05.396507Z",
     "iopub.status.busy": "2025-10-07T06:01:05.395947Z",
     "iopub.status.idle": "2025-10-07T06:03:17.786663Z",
     "shell.execute_reply": "2025-10-07T06:03:17.785841Z",
     "shell.execute_reply.started": "2025-10-07T06:01:05.396487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting CULane model evaluation (Instance-Level)...\n",
      "Loading model from checkpoint: /kaggle/input/culane-attention-module-trained-model/culane_attention_module_trained_model/best_model_culane_attention.pth.tar\n",
      "Loaded 9675 images for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Instances: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 605/605 [02:09<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "âœ… CULANE - FINAL INSTANCE-LEVEL METRICS\n",
      "=============================================\n",
      "Total True Positives (Correctly Detected Lanes):  13440\n",
      "Total False Positives (Incorrect Detections): 32057\n",
      "Total False Negatives (Missed Lanes):         16083\n",
      "---------------------------------------------\n",
      "Accuracy (Paper's Definition): 0.2183\n",
      "Precision:                     0.2954\n",
      "Recall:                        0.4552\n",
      "F1-Score:                      0.3583\n",
      "=============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
